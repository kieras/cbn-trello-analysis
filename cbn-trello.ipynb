{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import datetime as dt\n",
    "import dateutil.parser as dp\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "from functools import partial\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up key, token and Service Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('keys.json') as file:\n",
    "    keys = json.load(file)\n",
    "    api_key = keys['trello']['api_key']\n",
    "    token = keys['trello']['token']\n",
    "    spreadsheet_key = keys['sheet']['spreadsheet_key']\n",
    "    sa_file = keys['sheet']['sa_file']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Sheet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sheet_date(sheet_date):\n",
    "    conversion_table = {\n",
    "        'January': '01',\n",
    "        'February': '02',\n",
    "        'March': '03',\n",
    "        'April': '04',\n",
    "        'May': '05',\n",
    "        'June': '06',\n",
    "        'July': '07',\n",
    "        'August': '08',\n",
    "        'September': '09',\n",
    "        'October': '10',\n",
    "        'November': '11',\n",
    "        'December': '12'\n",
    "    }\n",
    "    \n",
    "    month = conversion_table[sheet_date.split('-')[0].strip()]\n",
    "    year = sheet_date.split('-')[1].strip()\n",
    "    \n",
    "    return year + '-' + month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consolidated_sheet():\n",
    "    scope = ['https://spreadsheets.google.com/feeds']\n",
    "    credentials = ServiceAccountCredentials.from_json_keyfile_name(sa_file, scope)\n",
    "    service = build('sheets', 'v4', credentials=credentials)\n",
    "\n",
    "    SAMPLE_RANGE_NAME = 'Consolidated'\n",
    "    sheet = service.spreadsheets()\n",
    "    result = sheet.values().get(spreadsheetId=spreadsheet_key,\n",
    "                                range=SAMPLE_RANGE_NAME).execute()\n",
    "    values = result.get('values', [])\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_by_date():\n",
    "    table = get_consolidated_sheet()\n",
    "    \n",
    "    header_row = table[0]\n",
    "    columns = [value for index, value in enumerate(header_row) if value] \n",
    "    converted_columns = [ convert_sheet_date(x) for x in columns[1:]]\n",
    "    \n",
    "    total_row = [value for value in table if value and value[0] == 'Total'][0]\n",
    "    # getting only the executed column\n",
    "    total = [value for index, value in enumerate(total_row) if index % 3 == 0]\n",
    "\n",
    "    total.pop(0)\n",
    "    \n",
    "    total_by_date = [ [converted_columns[index], value] for index, value in enumerate(total)]\n",
    "    \n",
    "    return total_by_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ftes_dataframe():\n",
    "    # from deprecated sheet, it will never be changed\n",
    "    old_data = [\n",
    "        ['2020-03', 4.0],\n",
    "        ['2020-04', 6.15],\n",
    "        ['2020-05', 6.25],\n",
    "        ['2020-06', 6.0],\n",
    "        ['2020-07', 3.65],\n",
    "        ['2020-08', 4.57],\n",
    "        ['2020-09', 4.52],\n",
    "        ['2020-10', 4.9],\n",
    "        ['2020-11', 4.7]\n",
    "    ]\n",
    "    \n",
    "    new_data = get_total_by_date()\n",
    "    \n",
    "    full_data = old_data + new_data\n",
    "    \n",
    "    total_fte = pd.DataFrame(full_data, columns=['month_base', 'fte'])\n",
    "    \n",
    "    total_fte['month_base'] = pd.to_datetime(total_fte['month_base'])\n",
    "    total_fte['month'] = pd.PeriodIndex(total_fte['month_base'], freq='M')\n",
    "    total_fte['quarter'] = pd.PeriodIndex(total_fte['month_base'], freq='Q')\n",
    "    total_fte['fte'] = total_fte['fte'].astype(float)\n",
    "    \n",
    "    del total_fte['month_base']\n",
    "    \n",
    "    return total_fte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_fte = create_ftes_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_fte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Trello Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_trello_api(url):\n",
    "    headers = {\n",
    "       \"Accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    query = {\n",
    "       'key': api_key,\n",
    "       'token': token\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"GET\", url, headers=headers, params=query)\n",
    "    \n",
    "    if response.status_code > 299:\n",
    "        raise Exception('Something went wrong with the request {0} '\\\n",
    "                        'with status: {1}'.format(url, response.status_code))\n",
    "    \n",
    "    return json.loads(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_name):\n",
    "    with open(json_name) as file:\n",
    "        json_opened = json.load(file)\n",
    "           \n",
    "    return json_opened "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_json(json_name, content_to_write):\n",
    "    with open(json_name, 'w') as json_file:\n",
    "        json.dump(content_to_write, json_file, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_timestamp():\n",
    "    current_timestamp = dt.datetime.now().strftime('%d-%m-%Y')\n",
    "    \n",
    "    return current_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_for_dumping(name, current_timestamp):\n",
    "    if not os.path.exists('dumps'):\n",
    "        os.mkdir('dumps')\n",
    "    \n",
    "    if not os.path.exists('dumps/' + name):\n",
    "        os.mkdir('dumps/' + name)\n",
    "    \n",
    "    if not os.path.exists('dumps/' + name + '/' + current_timestamp):\n",
    "        os.mkdir('dumps/' + name + '/' + current_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_dump(board_name, dump_name, timestamp):\n",
    "    path = 'dumps/' + board_name + '/' + timestamp + '/dump_' + dump_name + '.json'\n",
    "    \n",
    "    file_opened = read_json(path)\n",
    "    \n",
    "    return file_opened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acessing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_board_by_name(board_name):\n",
    "    boards_url = f'https://api.trello.com/1/search?query={board_name}'\n",
    "    board = get_data_from_trello_api(boards_url)\n",
    "    \n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lists_by_board(board_name, board_id, current_timestamp):\n",
    "    lists_url = 'https://api.trello.com/1/boards/{0}/lists'\n",
    "    lists = get_data_from_trello_api(lists_url.format(board_id))\n",
    "          \n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_custom_fields_by_board(board_name, board_id, current_timestamp):\n",
    "    custom_fields_url = 'https://api.trello.com/1/boards/{0}/customFields'\n",
    "    \n",
    "    custom_fields = get_data_from_trello_api(custom_fields_url.format(board_id))\n",
    "    \n",
    "    return custom_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cards_by_board(board_name, board_id, current_timestamp):\n",
    "    cards_on_board_url = 'https://api.trello.com/1/boards/{0}/cards/?customFieldItems=true'\n",
    "    board_cards = get_data_from_trello_api(cards_on_board_url.format(board_id))\n",
    "    \n",
    "    return board_cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_boards_dump(board_name, current_timestamp):\n",
    "    boards = get_board_by_name(board_name)\n",
    "\n",
    "    name_of_dump = f'dumps/{board_name}/{current_timestamp}/dump_board.json'\n",
    "        \n",
    "    write_json(name_of_dump, boards)\n",
    "    \n",
    "    return name_of_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_board_from_dump(board_name, current_timestamp):\n",
    "    board = get_board_by_name_from_dump(board_name, current_timestamp)\n",
    "    id_board = board['boards'][0]['id']\n",
    "\n",
    "    return id_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lists_dump(board_name, board_id, current_timestamp):\n",
    "    lists = get_lists_by_board(board_name, board_id, current_timestamp)\n",
    "    \n",
    "    name_of_dump = f'dumps/{board_name}/{current_timestamp}/dump_lists.json'\n",
    "    write_json(name_of_dump, lists)\n",
    "        \n",
    "    return name_of_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_fields_dump(board_name, board_id, current_timestamp):\n",
    "    custom_fields = get_custom_fields_by_board(board_name, board_id, current_timestamp)\n",
    "        \n",
    "    name_of_dump = f'dumps/{board_name}/{current_timestamp}/dump_custom_field.json'\n",
    "    write_json(name_of_dump, custom_fields)\n",
    "        \n",
    "    return name_of_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cards_dump(board_name, board_id, current_timestamp):\n",
    "    board_cards = get_cards_by_board(board_name, board_id, current_timestamp)    \n",
    "       \n",
    "    name_of_dump = f'dumps/{board_name}/{current_timestamp}/dump_cards.json'\n",
    "    \n",
    "    write_json(name_of_dump, board_cards)\n",
    "            \n",
    "    return name_of_dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dumps_by_name(board_name, current_timestamp):\n",
    "    create_folder_for_dumping(board_name, current_timestamp)\n",
    "    \n",
    "    create_boards_dump(board_name, current_timestamp)\n",
    "    \n",
    "    board_id = get_id_board_from_dump(board_name, current_timestamp)\n",
    "    \n",
    "    create_lists_dump(board_name, board_id, current_timestamp)\n",
    "    create_custom_fields_dump(board_name, board_id, current_timestamp)\n",
    "    create_cards_dump(board_name, board_id, current_timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data from dumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_board_by_name_from_dump(board_name, timestamp):\n",
    "    board = get_data_from_dump(board_name, 'board', timestamp)\n",
    "    \n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_lists_by_board_from_dump(board_name, timestamp):\n",
    "    lists_json = get_data_from_dump(board_name, 'lists', timestamp)\n",
    "    \n",
    "    list_map = {}\n",
    "    for list in lists_json:\n",
    "        list_map[list['id']] = list['name']\n",
    "    \n",
    "    return list_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_custom_fields_by_board_from_dump(board_name, timestamp):\n",
    "    custom_fields_json = get_data_from_dump(board_name, 'custom_field', timestamp)\n",
    "    \n",
    "    custom_field_map = {}\n",
    "    for custom_field in custom_fields_json:\n",
    "        custom_field_map[custom_field['id']] = custom_field['name']\n",
    "    \n",
    "    return custom_field_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_useful_cards_by_board(board_name, timestamp):\n",
    "    cards_raw = get_data_from_dump(board_name, 'cards' , timestamp)\n",
    "        \n",
    "    fields = ('id', 'name', 'idList', 'shortUrl', 'customFieldItems')\n",
    "\n",
    "    cards = [{key : value for key, value in card.items() if key in fields} for card in cards_raw ]\n",
    "\n",
    "    custom_fields_map = mapping_custom_fields_by_board_from_dump(board_name, timestamp)\n",
    "\n",
    "    lists_map = mapping_lists_by_board_from_dump(board_name, timestamp)\n",
    "\n",
    "    useful_cards = []\n",
    "    for card in cards:\n",
    "        idListName = lists_map[card['idList']]\n",
    "        if idListName in ['Done']:\n",
    "            normalized_card = {}\n",
    "\n",
    "            for custom_field in card['customFieldItems']:\n",
    "                name = custom_fields_map[custom_field['idCustomField']]\n",
    "                if name in ['Start', 'End', 'EndDev']:\n",
    "                    value = custom_field['value']['date']\n",
    "                    normalized_card[name] = value\n",
    "\n",
    "            if len(normalized_card) < 3:\n",
    "                raise Exception(\n",
    "                    'Make sure all dates are filled in the card: Start, EndDev and End for {0}'.format(card['name']))\n",
    "\n",
    "            normalized_card['name'] = card['name']\n",
    "            normalized_card['shortUrl'] = card['shortUrl']\n",
    "            normalized_card['idList'] = lists_map[card['idList']]\n",
    "            useful_cards.append(normalized_card)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return useful_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_trello(board_name, timestamp):\n",
    "    cards = get_useful_cards_by_board(board_name, timestamp)\n",
    "    df = pd.DataFrame.from_dict(cards)\n",
    "\n",
    "    df['dev_duration'] = (pd.to_datetime(df['EndDev']).dt.date - pd.to_datetime(df['Start']).dt.date).dt.days\n",
    "    df['duration'] = (pd.to_datetime(df['End']).dt.date - pd.to_datetime(df['Start']).dt.date).dt.days\n",
    "    \n",
    "    df['busday_dev_duration'] = np.busday_count(\n",
    "        pd.to_datetime(df['Start']).dt.date,\n",
    "        pd.to_datetime(df['EndDev']).dt.date)\n",
    "    \n",
    "    df['busday_duration'] = np.busday_count(\n",
    "        pd.to_datetime(df['Start']).dt.date,\n",
    "        pd.to_datetime(df['End']).dt.date)\n",
    "    \n",
    "    df['quarter'] = pd.PeriodIndex(df['End'], freq='Q')\n",
    "    \n",
    "    df['month'] = pd.PeriodIndex(df['End'], freq='M')\n",
    "\n",
    "    df[\"count\"] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "current_timestamp = generate_timestamp()\n",
    "create_dumps_by_name('CBN', current_timestamp)\n",
    "df = create_dataframe_from_trello('CBN', current_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancelled = df[(df['idList'] == 'Cancelled')]\n",
    "done = df[(df['idList'] == 'Done')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating General Estimatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extremes(data_frame, duration_column):\n",
    "    upper_q = partial(pd.Series.quantile, q=0.95)\n",
    "    lower_q = partial(pd.Series.quantile, q=0.05)\n",
    "\n",
    "    upper_extremes = data_frame[duration_column].agg([upper_q])[\"quantile\"]\n",
    "    lower_extremes = data_frame[duration_column].agg([lower_q])[\"quantile\"]\n",
    "    \n",
    "    return lower_extremes, upper_extremes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_estimatives_by_duration_column(data_frame, duration_column, print_results=True):\n",
    "    lower_extremes, upper_extremes = get_extremes(data_frame, duration_column)\n",
    "    \n",
    "    done_extremes_removed = data_frame[(data_frame[duration_column] > lower_extremes) & (data_frame[duration_column] < upper_extremes)]\n",
    "    mean_removed_extremes = done_extremes_removed[duration_column].mean()\n",
    "    \n",
    "    small_q = partial(pd.Series.quantile, q=0.25)\n",
    "    small_limit = done_extremes_removed[duration_column].agg([small_q])[\"quantile\"]\n",
    "    \n",
    "    small_extremes_removed = done_extremes_removed[(done_extremes_removed[duration_column] <= small_limit)]\n",
    "    not_small_extremes_removed = done_extremes_removed[(done_extremes_removed[duration_column] > small_limit)]\n",
    "    \n",
    "    mean_small_extremes_removed = small_extremes_removed[duration_column].mean()\n",
    "    mean_not_small_extremes_removed = not_small_extremes_removed[duration_column].mean()\n",
    "    \n",
    "    total_developed = len(data_frame)\n",
    "    \n",
    "    if print_results:\n",
    "        features = ('lower_extremes', 'upper_extremes', 'small limit', 'Done estimate (with \"extremes\" removed)',\n",
    "                   'Done estimate for \"Small\" ones', 'Done estimate for \"Big\" ones', 'Total_developed')\n",
    "        values = (lower_extremes, upper_extremes, small_limit, mean_removed_extremes, mean_small_extremes_removed, \n",
    "                 mean_not_small_extremes_removed, total_developed)\n",
    "        general_estimatives = {'Feature':features, 'Value':values}\n",
    "        general_estimatives_df = pd.DataFrame(data=general_estimatives)\n",
    "        display(general_estimatives_df)\n",
    "    \n",
    "    return done_extremes_removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_estimatives(data_frame):\n",
    "    display(Markdown('### Total Duration:'))\n",
    "    calculate_estimatives_by_duration_column(data_frame, 'duration')\n",
    "    print('\\n')\n",
    "    display(Markdown('### Total Dev Duration:'))\n",
    "    calculate_estimatives_by_duration_column(data_frame, 'dev_duration')\n",
    "    print('\\n')\n",
    "    display(Markdown('## BUSINESS DAY'))\n",
    "    print('\\n')\n",
    "    display(Markdown('### Business Day Duration:'))\n",
    "    calculate_estimatives_by_duration_column(data_frame, 'busday_duration')\n",
    "    print('\\n')\n",
    "    display(Markdown('### Business Day Dev Duration:'))\n",
    "    calculate_estimatives_by_duration_column(data_frame, 'busday_dev_duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_table_amount_delivered_by_period(df, total_fte, period): # quarter or month\n",
    "    by_period = df[[period, 'count']].groupby(period).sum('count')\n",
    "\n",
    "    by_period_fte = pd.merge(by_period, total_fte, on=period, how='left')\n",
    "\n",
    "    period_result = by_period_fte[[period, 'count', 'fte']].groupby([period,'count']).sum('fte')\n",
    "    period_result.reset_index(drop=False, inplace=True)\n",
    "\n",
    "    period_result['parsers_per_fte'] = period_result['count'].div(period_result['fte'])\n",
    "\n",
    "    period_result[period] = period_result[period].astype(str)\n",
    "\n",
    "    return period_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chart_amount_delivered_by_period(df, period):\n",
    "    ax = df[[period,'fte', 'parsers_per_fte']].plot(x=period, linestyle='-', marker='o', color=['orange', 'pink'])\n",
    "    df[[period,'count']].plot(x=period, kind='bar', ax=ax)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chart_and_table_amount_delivered_by_period(df, total_fte, period):\n",
    "    if period in ('month', 'quarter'):\n",
    "        period_result = generate_table_amount_delivered_by_period(df, total_fte, period)\n",
    "        generate_chart_amount_delivered_by_period(period_result, period)\n",
    "    else:\n",
    "        raise Exception(f'\"{period}\" is not defined. Must be \"month\" or \"quarter\".')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Estimatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_estimatives(done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amount delivered by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generate_chart_and_table_amount_delivered_by_period(df, total_fte, 'month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amount delivered by quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "generate_chart_and_table_amount_delivered_by_period(df, total_fte, 'quarter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_custom_fields_value_by_board_from_dump(board_name, timestamp):\n",
    "    custom_fields_json = get_data_from_dump(board_name, 'custom_field', timestamp)\n",
    "    \n",
    "    custom_field_map = {}\n",
    "    for custom_field in custom_fields_json:\n",
    "        if 'options' in custom_field.keys():\n",
    "            for options in custom_field['options']:\n",
    "                custom_field_map[options['id']] = options['value']['text']\n",
    "                #print(options)\n",
    "    \n",
    "    return custom_field_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_useful_cards_by_board_predict(board_name, timestamp):\n",
    "    cards_raw = get_data_from_dump(board_name, 'cards' , timestamp)\n",
    "        \n",
    "    fields = ('id', 'name', 'idList', 'shortUrl', 'customFieldItems')\n",
    "\n",
    "    cards = [{key : value for key, value in card.items() if key in fields} for card in cards_raw ]\n",
    "\n",
    "    custom_fields_map = mapping_custom_fields_by_board_from_dump(board_name, timestamp)\n",
    "    options_custom_fields_map = mapping_custom_fields_value_by_board_from_dump(board_name, timestamp)\n",
    "    #print(teste)\n",
    "\n",
    "    lists_map = mapping_lists_by_board_from_dump(board_name, timestamp)\n",
    "\n",
    "    useful_cards = []\n",
    "    for card in cards:\n",
    "        idListName = lists_map[card['idList']]\n",
    "        if idListName in ['Done']:\n",
    "            normalized_card = {}\n",
    "\n",
    "            for custom_field in card['customFieldItems']:\n",
    "                name = custom_fields_map[custom_field['idCustomField']]\n",
    "                if 'value' in custom_field.keys():\n",
    "                    value = custom_field['value'][list(custom_field['value'].keys())[0]]\n",
    "                    normalized_card[name] = value\n",
    "                elif 'idValue' in custom_field.keys():\n",
    "                    name_option = options_custom_fields_map[custom_field['idValue']]\n",
    "                    normalized_card[name] = name_option\n",
    "                    \n",
    "\n",
    "            normalized_card['name'] = card['name']\n",
    "            normalized_card['shortUrl'] = card['shortUrl']\n",
    "            normalized_card['idList'] = lists_map[card['idList']]\n",
    "            useful_cards.append(normalized_card)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return useful_cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe_from_trello_predict(board_name, timestamp):\n",
    "    cards = get_useful_cards_by_board_predict(board_name, timestamp)\n",
    "    df = pd.DataFrame.from_dict(cards)\n",
    "\n",
    "    df['dev_duration'] = (pd.to_datetime(df['EndDev']).dt.date - pd.to_datetime(df['Start']).dt.date).dt.days\n",
    "    df['duration'] = (pd.to_datetime(df['End']).dt.date - pd.to_datetime(df['Start']).dt.date).dt.days\n",
    "    \n",
    "    df['busday_dev_duration'] = np.busday_count(\n",
    "        pd.to_datetime(df['Start']).dt.date,\n",
    "        pd.to_datetime(df['EndDev']).dt.date)\n",
    "    \n",
    "    df['busday_duration'] = np.busday_count(\n",
    "        pd.to_datetime(df['Start']).dt.date,\n",
    "        pd.to_datetime(df['End']).dt.date)\n",
    "    \n",
    "    df['quarter'] = pd.PeriodIndex(df['End'], freq='Q')\n",
    "    \n",
    "    df['month'] = pd.PeriodIndex(df['End'], freq='M')\n",
    "\n",
    "    df[\"count\"] = 1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "current_timestamp = generate_timestamp()\n",
    "create_dumps_by_name('CBN', current_timestamp)\n",
    "df_predict = create_dataframe_from_trello_predict('CBN', current_timestamp)\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = df_predict[pd.notna(df_predict['Size/Complexity'] )]\n",
    "q_low = df_predict[\"duration\"].quantile(0.01)\n",
    "q_hi  = df_predict[\"duration\"].quantile(0.93)\n",
    "\n",
    "df_predict = df_predict[(df_predict[\"duration\"] < q_hi) & (df_predict[\"duration\"] > q_low)]\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separando features e labels\n",
    "features = df_predict.drop(['Buganizer', 'name', 'shortUrl', 'End', 'idList', 'CL', \n",
    "                            'Commit Date (by Google)', 'Date requested (by Google)', \n",
    "                            'EndDev', 'Start', 'quarter', 'month', 'Customers', \n",
    "                            'busday_dev_duration', 'busday_duration', 'dev_duration', \n",
    "                            'duration', 'count', 'Size/Complexity'], 1)\n",
    "labels = df_predict['duration']\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dummies = pd.get_dummies(features)\n",
    "features_dummies.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_dummies.dropna(inplace=True)\n",
    "features_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Escolhendo as melhores features com Kbest\n",
    "\n",
    "features_list = tuple(features_dummies.columns)\n",
    "\n",
    "k_best_features = SelectKBest(k='all')\n",
    "k_best_features.fit_transform(features_dummies, labels)\n",
    "k_best_features_scores = k_best_features.scores_\n",
    "raw_pairs = zip(features_list[1:], k_best_features_scores)\n",
    "ordered_pairs = list(reversed(sorted(raw_pairs, key=lambda x: x[1])))\n",
    "\n",
    "k_best_features_final = dict(ordered_pairs)\n",
    "\n",
    "print (\"Features:\")\n",
    "print (k_best_features_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = list(k_best_features_final.keys())[:12]\n",
    "features_dummies = features_dummies.loc[:,best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando os dados de treino teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_dummies, labels, test_size=0.15, random_state=10)\n",
    "\n",
    "print( len(X_train), len(y_train))\n",
    "print( len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinamento usando regressão linear\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "pred= lr.predict(X_test)\n",
    "\n",
    "cd =r2_score(y_test, pred)\n",
    "print(f'Coeficiente de determinação:{cd * 100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural padrão\n",
    "rn = MLPRegressor(max_iter=2000)\n",
    "\n",
    "rn.fit(X_train, y_train)\n",
    "pred= rn.predict(X_test)\n",
    "\n",
    "#cd = rn.score(X_test, y_test)\n",
    "cd =r2_score(y_test, pred)\n",
    "print(f'Coeficiente de determinação:{cd * 100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural com ajuste hyper parameters\n",
    "\n",
    "rn_new = MLPRegressor()\n",
    "\n",
    "parameter_space = {\n",
    "        'hidden_layer_sizes': [(i,) for i in list(range(1, 21))],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'solver': ['sgd', 'adam', 'lbfgs'], \n",
    "        'alpha': [0.0001, 0.05],\n",
    "        'learning_rate': ['constant', 'adaptive'],\n",
    "    }\n",
    "\n",
    "search = GridSearchCV(rn_new, parameter_space, n_jobs=-1, cv=5)\n",
    "\n",
    "search.fit(X_train,y_train)\n",
    "clf = search.best_estimator_\n",
    "\n",
    "pred = search.predict(X_test)\n",
    "\n",
    "#cd = search.score(X_test, y_test)\n",
    "cd =r2_score(y_test, pred)\n",
    "print(search.best_params_)\n",
    "print(f'Coeficiente de determinação:{cd * 100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede neural com ajuste hyper parameters fixos\n",
    "rn_adjust = MLPRegressor(activation='tanh', alpha=0.05, hidden_layer_sizes=(3,), learning_rate='constant', solver='sgd')\n",
    "rn_adjust.fit(X_train, y_train)\n",
    "\n",
    "pred = rn_adjust.predict(X_test)\n",
    "\n",
    "#cd = rn_adjust.score(X_test, y_test)\n",
    "cd =r2_score(y_test, pred)\n",
    "print(f'Coeficiente de determinação:{cd * 100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executando a previsão\n",
    "\n",
    "pred_lr = lr.predict(X_test)\n",
    "\n",
    "pred_rn = rn.predict(X_test)\n",
    "\n",
    "pred_rn_adjust_search = clf.predict(X_test)\n",
    "\n",
    "pred_rn_adjust = rn_adjust.predict(X_test)\n",
    "\n",
    "pred_lr_features = lr.predict(features_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(y_test, y_pred):\n",
    "    df_diff = np.absolute(np.round(y_test - y_pred))\n",
    "    count = 0\n",
    "    for value in df_diff:\n",
    "        if value <= 7:\n",
    "            count += 1\n",
    "    accuracy = 100 * (count/len(df_diff))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predição Linear Regression')\n",
    "print('Erro médio quadrático: ', mean_squared_error(y_test, pred_lr))\n",
    "print('Erro médio absoluto: ', mean_absolute_error(y_test, pred_lr))\n",
    "print('Média real: ', y_test.mean())\n",
    "print('Média predição: ', pred_lr.mean())\n",
    "print('Acurácia: ', model_accuracy(y_test, pred_lr), '%')\n",
    "display(pd.DataFrame({'real':y_test, 'previsao':pred_lr}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Predição Rede Neural Ajustada')\n",
    "print('Erro médio quadrático: ', mean_squared_error(y_test, pred_rn_adjust))\n",
    "print('Erro médio absoluto: ', mean_absolute_error(y_test, pred_rn_adjust))\n",
    "print('Média real: ', y_test.mean())\n",
    "print('Média predição: ', pred_rn_adjust.mean())\n",
    "print('Acurácia: ', model_accuracy(y_test, pred_rn_adjust), '%')\n",
    "display(pd.DataFrame({'real':y_test, 'previsao':pred_rn_adjust}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Predição Rede Neural Padrão')\n",
    "print('Erro médio quadrático: ', mean_squared_error(y_test, pred_rn))\n",
    "print('Erro médio absoluto: ', mean_absolute_error(y_test, pred_rn))\n",
    "print('Média real: ', y_test.mean())\n",
    "print('Média predição: ', pred_rn.mean())\n",
    "print('Acurácia: ', model_accuracy(y_test, pred_rn), '%')\n",
    "display(pd.DataFrame({'real':y_test, 'previsao':pred_rn}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Predição Rede Neural Ajustada Busca')\n",
    "print('Erro médio quadrático: ', mean_squared_error(y_test, pred_rn_adjust_search))\n",
    "print('Erro médio absoluto: ', mean_absolute_error(y_test, pred_rn_adjust_search))\n",
    "print('Média real: ', y_test.mean())\n",
    "print('Média predição: ', pred_rn_adjust_search.mean())\n",
    "print('Acurácia: ', model_accuracy(y_test, pred_rn_adjust_search), '%')\n",
    "display(pd.DataFrame({'real':y_test, 'previsao':pred_rn_adjust_search}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predição Linear Regression all labels')\n",
    "print('Erro médio quadrático: ', mean_squared_error(labels, pred_lr_features))\n",
    "print('Erro médio absoluto: ', mean_absolute_error(labels, pred_lr_features))\n",
    "print('Média real: ', labels.mean())\n",
    "print('Média predição: ', pred_lr_features.mean())\n",
    "print('Acurácia: ', model_accuracy(labels, pred_lr_features), '%')\n",
    "display(pd.DataFrame({'real':labels, 'previsao':pred_lr_features}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_table, X_test_table, y_train_table, y_test_table = train_test_split(df_predict, df_predict['duration'], test_size=0.15, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_table_cp = X_test_table\n",
    "X_test_table = X_test_table.drop(['duration', 'quarter', 'month', 'End'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_table['duration'] = np.absolute(np.round(pred_lr))\n",
    "\n",
    "X_test_table['End'] = pd.to_datetime(X_test_table['Start']) + pd.to_timedelta(X_test_table['duration'].astype(np.int),'D')\n",
    "    \n",
    "X_test_table['quarter'] = pd.PeriodIndex(X_test_table['End'], freq='Q')\n",
    "    \n",
    "X_test_table['month'] = pd.PeriodIndex(X_test_table['End'], freq='M')\n",
    "\n",
    "\n",
    "\n",
    "X_test_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([X_train_table, X_test_table])\n",
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Real')\n",
    "generate_chart_and_table_amount_delivered_by_period(df_predict, total_fte, 'month')\n",
    "print('Previsão')\n",
    "generate_chart_and_table_amount_delivered_by_period(df_full, total_fte, 'month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Real apenas teste')\n",
    "generate_chart_and_table_amount_delivered_by_period(X_test_table_cp, total_fte, 'month')\n",
    "print('Previsão apenas teste')\n",
    "generate_chart_and_table_amount_delivered_by_period(X_test_table, total_fte, 'month')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
